{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Saurabh_Agarwal_J001_DL_LabTest_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P12k4c9faXj1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "9b21e186-76d4-4642-955a-ef2d55781015"
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SalI6O_LaanM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "51772fc1-a09f-4237-c71f-95df847a8194"
      },
      "source": [
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lp0jE6zaap0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufr_1lFtaavy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "89388b9e-587d-4ac3-bbac-8b1c0f03e6c6"
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qajY1gTsaayI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "7ab2aeb5-769c-409d-c5c0-f76346f43348"
      },
      "source": [
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHy2RvnZaa41",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "abbd182a-d629-4afc-a023-c0a56f555431"
      },
      "source": [
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.2257 - acc: 0.9307 - val_loss: 0.1130 - val_acc: 0.9654\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0863 - acc: 0.9733 - val_loss: 0.1122 - val_acc: 0.9656\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0572 - acc: 0.9821 - val_loss: 0.0788 - val_acc: 0.9761\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0399 - acc: 0.9874 - val_loss: 0.0790 - val_acc: 0.9801\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0297 - acc: 0.9905 - val_loss: 0.0826 - val_acc: 0.9785\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0232 - acc: 0.9927 - val_loss: 0.0864 - val_acc: 0.9805\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0199 - acc: 0.9937 - val_loss: 0.0863 - val_acc: 0.9833\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0153 - acc: 0.9951 - val_loss: 0.1015 - val_acc: 0.9798\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0131 - acc: 0.9959 - val_loss: 0.0831 - val_acc: 0.9826\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0118 - acc: 0.9964 - val_loss: 0.1042 - val_acc: 0.9812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5fe2d1b588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzvWl-7_aa9z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "af9b92ce-5494-4755-83a5-f239545023b4"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.10416394962423646\n",
            "Test accuracy: 0.9812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPLjHvM3abAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "sgd=keras.optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRawZOApaa3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "7b295a2e-c71c-43ee-b1e1-f39354f5b593"
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0920 - val_acc: 0.9834\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0892 - val_acc: 0.9838\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0878 - val_acc: 0.9841\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0869 - val_acc: 0.9841\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0863 - val_acc: 0.9840\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0860 - val_acc: 0.9839\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0856 - val_acc: 0.9840\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0012 - acc: 0.9999 - val_loss: 0.0852 - val_acc: 0.9841\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0011 - acc: 0.9999 - val_loss: 0.0850 - val_acc: 0.9842\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0011 - acc: 0.9999 - val_loss: 0.0848 - val_acc: 0.9842\n",
            "Test loss: 0.08475178368201845\n",
            "Test accuracy: 0.9842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwGUFd2uaa09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "rms=keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z_L0kmTaaun",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "d82274df-a9ad-4e39-880e-c5d8bf9215d7"
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=rms,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.0117 - acc: 0.9962 - val_loss: 0.0965 - val_acc: 0.9813\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0084 - acc: 0.9973 - val_loss: 0.1021 - val_acc: 0.9824\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0079 - acc: 0.9977 - val_loss: 0.1195 - val_acc: 0.9802\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0071 - acc: 0.9979 - val_loss: 0.1328 - val_acc: 0.9798\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0073 - acc: 0.9980 - val_loss: 0.1195 - val_acc: 0.9825\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0053 - acc: 0.9986 - val_loss: 0.1376 - val_acc: 0.9799\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0046 - acc: 0.9984 - val_loss: 0.1240 - val_acc: 0.9828\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.1401 - val_acc: 0.9809\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0047 - acc: 0.9986 - val_loss: 0.1383 - val_acc: 0.9819\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0053 - acc: 0.9986 - val_loss: 0.1326 - val_acc: 0.9829\n",
            "Test loss: 0.13256596705135507\n",
            "Test accuracy: 0.9829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjsaSYqHaass",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "ada=keras.optimizers.Adagrad(lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVF8duhqbgox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "74194285-f28a-4960-ef7c-aea379d68fb2"
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=ada,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0370 - acc: 0.9952 - val_loss: 0.1220 - val_acc: 0.9840\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.1192 - val_acc: 0.9836\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 3.9666e-04 - acc: 1.0000 - val_loss: 0.1171 - val_acc: 0.9835\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 2.9254e-04 - acc: 1.0000 - val_loss: 0.1168 - val_acc: 0.9836\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 2.8609e-04 - acc: 1.0000 - val_loss: 0.1166 - val_acc: 0.9837\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 2.8394e-04 - acc: 1.0000 - val_loss: 0.1165 - val_acc: 0.9839\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 2.8250e-04 - acc: 1.0000 - val_loss: 0.1164 - val_acc: 0.9839\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 2.8143e-04 - acc: 1.0000 - val_loss: 0.1163 - val_acc: 0.9840\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 2.8058e-04 - acc: 1.0000 - val_loss: 0.1162 - val_acc: 0.9840\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 2.7988e-04 - acc: 1.0000 - val_loss: 0.1162 - val_acc: 0.9840\n",
            "Test loss: 0.11617956422023312\n",
            "Test accuracy: 0.984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8glagdlubgrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adelta=keras.optimizers.Adadelta(lr=1.0, rho=0.95)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Mzq9jx5bgwr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "db9f0254-dc5c-44ca-d700-1e4b7f15428e"
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adelta,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 124us/step - loss: 2.7950e-04 - acc: 1.0000 - val_loss: 0.1159 - val_acc: 0.9840\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 2.7764e-04 - acc: 1.0000 - val_loss: 0.1157 - val_acc: 0.9842\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 2.7668e-04 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 0.9843\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 2.7586e-04 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 0.9843\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 2.7522e-04 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9841\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 2.7475e-04 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9843\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 2.7439e-04 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9842\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 2.7404e-04 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9841\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 2.7375e-04 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9841\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 2.7350e-04 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9843\n",
            "Test loss: 0.11535763574511375\n",
            "Test accuracy: 0.9843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wlx90XObg0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeO2NcEIbgvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "72641cff-539a-4d65-ecb4-739f93c72653"
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0190 - acc: 0.9957 - val_loss: 0.1203 - val_acc: 0.9811\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0152 - acc: 0.9961 - val_loss: 0.1240 - val_acc: 0.9807\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0126 - acc: 0.9965 - val_loss: 0.1129 - val_acc: 0.9818\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0074 - acc: 0.9977 - val_loss: 0.1202 - val_acc: 0.9796\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0127 - acc: 0.9966 - val_loss: 0.1305 - val_acc: 0.9807\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0126 - acc: 0.9968 - val_loss: 0.1107 - val_acc: 0.9806\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0095 - acc: 0.9973 - val_loss: 0.1148 - val_acc: 0.9810\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0079 - acc: 0.9976 - val_loss: 0.1131 - val_acc: 0.9812\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0059 - acc: 0.9982 - val_loss: 0.1334 - val_acc: 0.9800\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0086 - acc: 0.9977 - val_loss: 0.1088 - val_acc: 0.9811\n",
            "Test loss: 0.10880497127624067\n",
            "Test accuracy: 0.9811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ4iVjCFbsqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "nadam=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Loo5_Os9bsuc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "d021444c-f6c1-4f3b-a4ac-eecbfe121f83"
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=nadam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 0.0371 - acc: 0.9917 - val_loss: 0.1451 - val_acc: 0.9765\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0272 - acc: 0.9933 - val_loss: 0.1177 - val_acc: 0.9792\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0207 - acc: 0.9945 - val_loss: 0.1241 - val_acc: 0.9805\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0223 - acc: 0.9943 - val_loss: 0.1339 - val_acc: 0.9744\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0211 - acc: 0.9941 - val_loss: 0.1251 - val_acc: 0.9780\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0221 - acc: 0.9944 - val_loss: 0.1300 - val_acc: 0.9770\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0167 - acc: 0.9955 - val_loss: 0.1364 - val_acc: 0.9787\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0231 - acc: 0.9940 - val_loss: 0.1460 - val_acc: 0.9775\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0188 - acc: 0.9954 - val_loss: 0.1508 - val_acc: 0.9783\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0137 - acc: 0.9963 - val_loss: 0.1429 - val_acc: 0.9796\n",
            "Test loss: 0.14294172103434152\n",
            "Test accuracy: 0.9796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsxpweUzbs0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBqCVcUAbs35",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "4b536f00-53d1-4a51-f476-758334d925f7"
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.1092 - val_acc: 0.9845\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 3.7971e-04 - acc: 1.0000 - val_loss: 0.1079 - val_acc: 0.9853\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 3.2373e-04 - acc: 1.0000 - val_loss: 0.1082 - val_acc: 0.9852\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 3.0513e-04 - acc: 1.0000 - val_loss: 0.1088 - val_acc: 0.9853\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 2.9324e-04 - acc: 1.0000 - val_loss: 0.1095 - val_acc: 0.9851\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 2.8506e-04 - acc: 1.0000 - val_loss: 0.1104 - val_acc: 0.9854\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 2.7946e-04 - acc: 1.0000 - val_loss: 0.1115 - val_acc: 0.9853\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 2.7550e-04 - acc: 1.0000 - val_loss: 0.1123 - val_acc: 0.9858\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 2.7300e-04 - acc: 1.0000 - val_loss: 0.1133 - val_acc: 0.9857\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 2.7145e-04 - acc: 1.0000 - val_loss: 0.1143 - val_acc: 0.9859\n",
            "Test loss: 0.11429675587820011\n",
            "Test accuracy: 0.9859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36K9QhkNbsxV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "9a781b27-4a80-4ca1-903a-79122aa4bde0"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvRoPNP1bspH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "a57cc947-77ee-45e4-acee-eafe648f74d8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrCAODjMzK4iDw8zMCvL/AZQFxuWag2m3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZJKLsd2b-7W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "d4cda022-881b-4336-cac3-27b898fd44b8"
      },
      "source": [
        "# Output network visualization\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"352pt\" viewBox=\"0.00 0.00 181.00 264.00\" width=\"241pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 260)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 177,-260 177,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140048809782240 -->\n<g class=\"node\" id=\"node1\">\n<title>140048809782240</title>\n<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 173,-255.5 173,-219.5 0,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-233.8\">dense_1_input: InputLayer</text>\n</g>\n<!-- 140048810184320 -->\n<g class=\"node\" id=\"node2\">\n<title>140048810184320</title>\n<polygon fill=\"none\" points=\"33,-146.5 33,-182.5 140,-182.5 140,-146.5 33,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-160.8\">dense_1: Dense</text>\n</g>\n<!-- 140048809782240&#45;&gt;140048810184320 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140048809782240-&gt;140048810184320</title>\n<path d=\"M86.5,-219.4551C86.5,-211.3828 86.5,-201.6764 86.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-192.5903 86.5,-182.5904 83.0001,-192.5904 90.0001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140049803986088 -->\n<g class=\"node\" id=\"node3\">\n<title>140049803986088</title>\n<polygon fill=\"none\" points=\"33,-73.5 33,-109.5 140,-109.5 140,-73.5 33,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-87.8\">dense_2: Dense</text>\n</g>\n<!-- 140048810184320&#45;&gt;140049803986088 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140048810184320-&gt;140049803986088</title>\n<path d=\"M86.5,-146.4551C86.5,-138.3828 86.5,-128.6764 86.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-119.5903 86.5,-109.5904 83.0001,-119.5904 90.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140048796757912 -->\n<g class=\"node\" id=\"node4\">\n<title>140048796757912</title>\n<polygon fill=\"none\" points=\"33,-.5 33,-36.5 140,-36.5 140,-.5 33,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-14.8\">dense_3: Dense</text>\n</g>\n<!-- 140049803986088&#45;&gt;140048796757912 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140049803986088-&gt;140048796757912</title>\n<path d=\"M86.5,-73.4551C86.5,-65.3828 86.5,-55.6764 86.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-46.5903 86.5,-36.5904 83.0001,-46.5904 90.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHQPcBTZb--Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}