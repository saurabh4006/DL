{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J043_DL_Test_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyS2_gJbvNBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "478beb83-bacf-4e60-ba14-151150fa7497"
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEQg-n3WwCXz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ac36af3e-1ac6-4c95-f1a4-a3119355ee6c"
      },
      "source": [
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7H4seB9wETJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgZBluTPwFat",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "a8d642c8-0806-44b7-808d-aebfdae7df7a"
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePwqr0hAxaxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "86af8ff8-6800-410e-f7f4-3899d4e434d9"
      },
      "source": [
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya5JgbGIxeI2",
        "colab_type": "code",
        "outputId": "0388c093-12a0-4391-c3cc-28fd7465abd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.2300 - acc: 0.9279 - val_loss: 0.1209 - val_acc: 0.9641\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0852 - acc: 0.9730 - val_loss: 0.0746 - val_acc: 0.9768\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0552 - acc: 0.9826 - val_loss: 0.0691 - val_acc: 0.9795\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0389 - acc: 0.9880 - val_loss: 0.0746 - val_acc: 0.9782\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0303 - acc: 0.9907 - val_loss: 0.0821 - val_acc: 0.9790\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0219 - acc: 0.9930 - val_loss: 0.1014 - val_acc: 0.9762\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0183 - acc: 0.9941 - val_loss: 0.0872 - val_acc: 0.9799\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0153 - acc: 0.9954 - val_loss: 0.0900 - val_acc: 0.9812\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0117 - acc: 0.9966 - val_loss: 0.0977 - val_acc: 0.9808\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0107 - acc: 0.9964 - val_loss: 0.1020 - val_acc: 0.9830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7feb05ad25f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsImmn3Sxga4",
        "colab_type": "code",
        "outputId": "f3498c59-62a7-4a1c-ff7c-5614d20782c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.10197307052112774\n",
            "Test accuracy: 0.983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG7NY4KExzeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "sgd=keras.optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR85dOWX2KVV",
        "colab_type": "code",
        "outputId": "7d1ebc79-a030-4e27-dc15-f9f75c3f3212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0909 - val_acc: 0.9840\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.0889 - val_acc: 0.9840\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0022 - acc: 0.9995 - val_loss: 0.0878 - val_acc: 0.9841\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0870 - val_acc: 0.9842\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0865 - val_acc: 0.9844\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0861 - val_acc: 0.9843\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0858 - val_acc: 0.9845\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0856 - val_acc: 0.9847\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.0013 - acc: 0.9999 - val_loss: 0.0854 - val_acc: 0.9848\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.0012 - acc: 0.9999 - val_loss: 0.0852 - val_acc: 0.9849\n",
            "Test loss: 0.0851982404758646\n",
            "Test accuracy: 0.9849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkwfC4QQ2L1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "rms=keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zErZfP1O2RtW",
        "colab_type": "code",
        "outputId": "42ca64bd-4669-4f02-ed8c-9c89242d3748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=rms,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.0102 - acc: 0.9969 - val_loss: 0.0991 - val_acc: 0.9831\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0085 - acc: 0.9973 - val_loss: 0.1149 - val_acc: 0.9799\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0071 - acc: 0.9980 - val_loss: 0.1150 - val_acc: 0.9807\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0071 - acc: 0.9978 - val_loss: 0.1123 - val_acc: 0.9830\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0072 - acc: 0.9979 - val_loss: 0.1167 - val_acc: 0.9826\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.1280 - val_acc: 0.9825\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0047 - acc: 0.9985 - val_loss: 0.1212 - val_acc: 0.9839\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.1407 - val_acc: 0.9813\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.1312 - val_acc: 0.9828\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.1547 - val_acc: 0.9795\n",
            "Test loss: 0.1546726021672189\n",
            "Test accuracy: 0.9795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ2O48p02SvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "ada=keras.optimizers.Adagrad(lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjd3iUUG2U-s",
        "colab_type": "code",
        "outputId": "e4d628ee-c591-4b9c-b1cd-15e8cb2317bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=ada,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0366 - acc: 0.9952 - val_loss: 0.1207 - val_acc: 0.9841\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.1132 - val_acc: 0.9842\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 7.7706e-04 - acc: 0.9999 - val_loss: 0.1197 - val_acc: 0.9841\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 5.8555e-04 - acc: 1.0000 - val_loss: 0.1170 - val_acc: 0.9843\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 5.6323e-04 - acc: 1.0000 - val_loss: 0.1170 - val_acc: 0.9845\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 5.5613e-04 - acc: 1.0000 - val_loss: 0.1169 - val_acc: 0.9845\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 5.5405e-04 - acc: 1.0000 - val_loss: 0.1169 - val_acc: 0.9844\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 5.5254e-04 - acc: 1.0000 - val_loss: 0.1169 - val_acc: 0.9845\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 5.5139e-04 - acc: 1.0000 - val_loss: 0.1169 - val_acc: 0.9845\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 5.5045e-04 - acc: 1.0000 - val_loss: 0.1169 - val_acc: 0.9844\n",
            "Test loss: 0.11691715078288478\n",
            "Test accuracy: 0.9844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0siIJN_2WLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adelta=keras.optimizers.Adadelta(lr=1.0, rho=0.95)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P52I7NVD2Z2N",
        "colab_type": "code",
        "outputId": "1d2fc0f8-35a4-4de5-e739-38c985b2e810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adelta,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 5.4974e-04 - acc: 1.0000 - val_loss: 0.1171 - val_acc: 0.9844\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 5.4777e-04 - acc: 1.0000 - val_loss: 0.1172 - val_acc: 0.9843\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 5.4649e-04 - acc: 1.0000 - val_loss: 0.1171 - val_acc: 0.9842\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 5.4559e-04 - acc: 1.0000 - val_loss: 0.1171 - val_acc: 0.9845\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 5.4487e-04 - acc: 1.0000 - val_loss: 0.1172 - val_acc: 0.9844\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 5.4432e-04 - acc: 1.0000 - val_loss: 0.1172 - val_acc: 0.9844\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 5.4384e-04 - acc: 1.0000 - val_loss: 0.1173 - val_acc: 0.9844\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 5.4345e-04 - acc: 1.0000 - val_loss: 0.1174 - val_acc: 0.9845\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 5.4310e-04 - acc: 1.0000 - val_loss: 0.1174 - val_acc: 0.9844\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 50us/step - loss: 5.4280e-04 - acc: 1.0000 - val_loss: 0.1175 - val_acc: 0.9845\n",
            "Test loss: 0.11754824173301974\n",
            "Test accuracy: 0.9845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSWuLFd22bRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-piKnWXC2cpJ",
        "colab_type": "code",
        "outputId": "a5b29711-83d4-4c1d-98f1-b3357ecd1c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0209 - acc: 0.9952 - val_loss: 0.1246 - val_acc: 0.9809\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.0118 - acc: 0.9970 - val_loss: 0.1584 - val_acc: 0.9764\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.0138 - acc: 0.9965 - val_loss: 0.1041 - val_acc: 0.9835\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.0082 - acc: 0.9975 - val_loss: 0.1108 - val_acc: 0.9810\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.0104 - acc: 0.9970 - val_loss: 0.1247 - val_acc: 0.9797\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.0084 - acc: 0.9976 - val_loss: 0.1403 - val_acc: 0.9765\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.0143 - acc: 0.9962 - val_loss: 0.1073 - val_acc: 0.9816\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.0099 - acc: 0.9975 - val_loss: 0.0961 - val_acc: 0.9822\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.0121 - acc: 0.9968 - val_loss: 0.0888 - val_acc: 0.9830\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0933 - val_acc: 0.9834\n",
            "Test loss: 0.09330282515701836\n",
            "Test accuracy: 0.9834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1uH7XZO2h79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "nadam=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLm5wKw12jwH",
        "colab_type": "code",
        "outputId": "a0046997-efb6-4527-97f7-eee9dbbf1ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=nadam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0310 - acc: 0.9923 - val_loss: 0.1188 - val_acc: 0.9784\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.0220 - acc: 0.9940 - val_loss: 0.1248 - val_acc: 0.9768\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.0176 - acc: 0.9947 - val_loss: 0.1195 - val_acc: 0.9777\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.0196 - acc: 0.9948 - val_loss: 0.1159 - val_acc: 0.9783\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.0212 - acc: 0.9939 - val_loss: 0.1283 - val_acc: 0.9779\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.0177 - acc: 0.9949 - val_loss: 0.1595 - val_acc: 0.9726\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.0152 - acc: 0.9956 - val_loss: 0.1232 - val_acc: 0.9788\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0201 - acc: 0.9948 - val_loss: 0.1190 - val_acc: 0.9790\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0169 - acc: 0.9953 - val_loss: 0.1085 - val_acc: 0.9808\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0163 - acc: 0.9956 - val_loss: 0.1181 - val_acc: 0.9807\n",
            "Test loss: 0.11814198203409858\n",
            "Test accuracy: 0.9807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMpzVB7K2lgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG4so5lh4sw5",
        "colab_type": "code",
        "outputId": "1ff4fd4a-2934-45ca-c89e-563a6d4860d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.1017 - val_acc: 0.9847\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 6.5731e-04 - acc: 1.0000 - val_loss: 0.1006 - val_acc: 0.9848\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 5.8490e-04 - acc: 1.0000 - val_loss: 0.1018 - val_acc: 0.9846\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 5.6714e-04 - acc: 1.0000 - val_loss: 0.1028 - val_acc: 0.9848\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 5.5723e-04 - acc: 1.0000 - val_loss: 0.1039 - val_acc: 0.9849\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 5.5062e-04 - acc: 1.0000 - val_loss: 0.1049 - val_acc: 0.9848\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 5.4583e-04 - acc: 1.0000 - val_loss: 0.1063 - val_acc: 0.9853\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 5.4277e-04 - acc: 1.0000 - val_loss: 0.1079 - val_acc: 0.9854\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 5.4070e-04 - acc: 1.0000 - val_loss: 0.1091 - val_acc: 0.9853\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 5.3939e-04 - acc: 1.0000 - val_loss: 0.1108 - val_acc: 0.9854\n",
            "Test loss: 0.11084884446877234\n",
            "Test accuracy: 0.9854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtwcZGOF9mpR",
        "colab_type": "code",
        "outputId": "3f1cd529-f4db-4e7a-c92f-f74937722cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_dARhw94sp-",
        "colab_type": "code",
        "outputId": "3fa165c1-a2a8-4bea-93a4-0ba751ed212b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJrRqmzK5GH4",
        "colab_type": "code",
        "outputId": "f42b5a68-4e72-4076-a711-729c0bf8e657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "source": [
        "# Output network visualization\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"352pt\" viewBox=\"0.00 0.00 181.00 264.00\" width=\"241pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 260)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 177,-260 177,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140647402512848 -->\n<g class=\"node\" id=\"node1\">\n<title>140647402512848</title>\n<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 173,-255.5 173,-219.5 0,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-233.8\">dense_1_input: InputLayer</text>\n</g>\n<!-- 140648396719608 -->\n<g class=\"node\" id=\"node2\">\n<title>140648396719608</title>\n<polygon fill=\"none\" points=\"33,-146.5 33,-182.5 140,-182.5 140,-146.5 33,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-160.8\">dense_1: Dense</text>\n</g>\n<!-- 140647402512848&#45;&gt;140648396719608 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140647402512848-&gt;140648396719608</title>\n<path d=\"M86.5,-219.4551C86.5,-211.3828 86.5,-201.6764 86.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-192.5903 86.5,-182.5904 83.0001,-192.5904 90.0001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140648396720224 -->\n<g class=\"node\" id=\"node3\">\n<title>140648396720224</title>\n<polygon fill=\"none\" points=\"33,-73.5 33,-109.5 140,-109.5 140,-73.5 33,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-87.8\">dense_2: Dense</text>\n</g>\n<!-- 140648396719608&#45;&gt;140648396720224 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140648396719608-&gt;140648396720224</title>\n<path d=\"M86.5,-146.4551C86.5,-138.3828 86.5,-128.6764 86.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-119.5903 86.5,-109.5904 83.0001,-119.5904 90.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140647389482400 -->\n<g class=\"node\" id=\"node4\">\n<title>140647389482400</title>\n<polygon fill=\"none\" points=\"33,-.5 33,-36.5 140,-36.5 140,-.5 33,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-14.8\">dense_3: Dense</text>\n</g>\n<!-- 140648396720224&#45;&gt;140647389482400 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140648396720224-&gt;140647389482400</title>\n<path d=\"M86.5,-73.4551C86.5,-65.3828 86.5,-55.6764 86.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-46.5903 86.5,-36.5904 83.0001,-46.5904 90.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}